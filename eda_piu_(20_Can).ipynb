{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b6985047",
      "metadata": {
        "papermill": {
          "duration": 0.016296,
          "end_time": "2024-12-17T16:35:21.765828",
          "exception": false,
          "start_time": "2024-12-17T16:35:21.749532",
          "status": "completed"
        },
        "tags": [],
        "id": "b6985047"
      },
      "source": [
        "# 1. Import library\n",
        "Import all necessary libraries throughout the project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b60e1c69",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-17T16:35:21.784688Z",
          "iopub.status.busy": "2024-12-17T16:35:21.784371Z",
          "iopub.status.idle": "2024-12-17T16:35:56.204783Z",
          "shell.execute_reply": "2024-12-17T16:35:56.203897Z"
        },
        "papermill": {
          "duration": 34.43206,
          "end_time": "2024-12-17T16:35:56.206787",
          "exception": false,
          "start_time": "2024-12-17T16:35:21.774727",
          "status": "completed"
        },
        "tags": [],
        "id": "b60e1c69"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import seaborn as sns\n",
        "from sklearn.base import clone, BaseEstimator, RegressorMixin\n",
        "from sklearn.metrics import cohen_kappa_score, accuracy_score, mean_squared_error\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.datasets import make_classification\n",
        "from scipy.optimize import minimize\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "import missingno as msno\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense\n",
        "from keras.optimizers import Adam\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from colorama import Fore, Style\n",
        "from IPython.display import clear_output\n",
        "import warnings\n",
        "from lightgbm import LGBMRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.ensemble import VotingRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.impute import SimpleImputer, KNNImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.options.display.max_columns = None\n",
        "\n",
        "from bayes_opt import BayesianOptimization\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68c10753",
      "metadata": {
        "papermill": {
          "duration": 0.008212,
          "end_time": "2024-12-17T16:35:56.223980",
          "exception": false,
          "start_time": "2024-12-17T16:35:56.215768",
          "status": "completed"
        },
        "tags": [],
        "id": "68c10753"
      },
      "source": [
        "### Helper function\n",
        "These functions help us to read and preprocess parquet data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a63264f2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-17T16:35:56.241590Z",
          "iopub.status.busy": "2024-12-17T16:35:56.240946Z",
          "iopub.status.idle": "2024-12-17T16:35:56.247075Z",
          "shell.execute_reply": "2024-12-17T16:35:56.246303Z"
        },
        "papermill": {
          "duration": 0.016638,
          "end_time": "2024-12-17T16:35:56.248596",
          "exception": false,
          "start_time": "2024-12-17T16:35:56.231958",
          "status": "completed"
        },
        "tags": [],
        "id": "a63264f2"
      },
      "outputs": [],
      "source": [
        "def process_file(filename, dirname):\n",
        "    \"\"\"\n",
        "    Reads a Parquet file, processes its contents,\n",
        "    and returns n time series value extracted from the data and an id of a volunteer.\n",
        "\n",
        "    Parameters:\n",
        "        dirname (str): The directory path where the file is located.\n",
        "        filename (str): The filename of the Parquet file to be read. The file is expected to be in a subdirectory\n",
        "                        named after the `filename` parameter, containing a part file named 'part-0.parquet'.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing:\n",
        "            - numpy.ndarray: Flattened time series data of the DataFrame (excluding the 'step' column).\n",
        "            - str: A substring extracted from the `filename`, split by '=' - this is an ID of the volunteer\n",
        "             and returning the second part.\n",
        "    \"\"\"\n",
        "    df = pd.read_parquet(os.path.join(dirname, filename, 'part-0.parquet'))\n",
        "    df.drop('step', axis=1, inplace=True)\n",
        "    return df.describe().values.reshape(-1), filename.split('=')[1]\n",
        "\n",
        "def load_time_series(dirname) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "      Loads and preprocesses time series data from multiple files in a directory,\n",
        "      returning a DataFrame containing n time series features for each volunteer.\n",
        "\n",
        "      Parameters:\n",
        "          dirname (str): The directory path containing the time series files to preprocess.\n",
        "\n",
        "      Returns:\n",
        "          pd.DataFrame: A DataFrame with the following structure:\n",
        "              - Columns `stat_0`, `stat_1`, ..., `stat_n`: n time series features extracted from each file.\n",
        "              - Column `id`: The unique identifiers (derived from filenames) for each volunteer.\n",
        "    \"\"\"\n",
        "    ids = os.listdir(dirname)\n",
        "\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        results = list(tqdm(executor.map(lambda fname: process_file(fname, dirname), ids), total=len(ids)))\n",
        "\n",
        "    stats, indexes = zip(*results)\n",
        "\n",
        "    df = pd.DataFrame(stats, columns=[f\"stat_{i}\" for i in range(len(stats[0]))])\n",
        "    df['id'] = indexes\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f27c4c4a",
      "metadata": {
        "papermill": {
          "duration": 0.008947,
          "end_time": "2024-12-17T16:35:56.266683",
          "exception": false,
          "start_time": "2024-12-17T16:35:56.257736",
          "status": "completed"
        },
        "tags": [],
        "id": "f27c4c4a"
      },
      "source": [
        "# 2. Read data\n",
        "This section is the data loading CSV and time series data, extract time series data part."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdfbd30e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-17T16:35:56.284134Z",
          "iopub.status.busy": "2024-12-17T16:35:56.283900Z",
          "iopub.status.idle": "2024-12-17T16:37:08.110970Z",
          "shell.execute_reply": "2024-12-17T16:37:08.109957Z"
        },
        "papermill": {
          "duration": 71.837898,
          "end_time": "2024-12-17T16:37:08.112891",
          "exception": false,
          "start_time": "2024-12-17T16:35:56.274993",
          "status": "completed"
        },
        "tags": [],
        "id": "fdfbd30e"
      },
      "outputs": [],
      "source": [
        "# Reading training and test data (CSV)\n",
        "train = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/train.csv')\n",
        "test = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/test.csv')\n",
        "sample = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/sample_submission.csv')\n",
        "dict = pd.read_csv('../input/child-mind-institute-problematic-internet-use/data_dictionary.csv')\n",
        "\n",
        "# Reading and preprocessing time series data from .parquet file\n",
        "train_ts = load_time_series(\"/kaggle/input/child-mind-institute-problematic-internet-use/series_train.parquet\")\n",
        "test_ts = load_time_series(\"/kaggle/input/child-mind-institute-problematic-internet-use/series_test.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4c89e8d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-17T16:37:08.159210Z",
          "iopub.status.busy": "2024-12-17T16:37:08.158405Z",
          "iopub.status.idle": "2024-12-17T16:37:08.183428Z",
          "shell.execute_reply": "2024-12-17T16:37:08.182693Z"
        },
        "papermill": {
          "duration": 0.049355,
          "end_time": "2024-12-17T16:37:08.185092",
          "exception": false,
          "start_time": "2024-12-17T16:37:08.135737",
          "status": "completed"
        },
        "tags": [],
        "id": "a4c89e8d"
      },
      "outputs": [],
      "source": [
        "# Check if the timeseries data has labels\n",
        "combine = pd.merge(train_ts, train[['id', 'sii']], on='id', how='left')\n",
        "# Check the number of data points without labels\n",
        "combine['sii'].isna().sum()\n",
        "# => All data in the timeseries have labels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23972ef0",
      "metadata": {
        "papermill": {
          "duration": 0.023757,
          "end_time": "2024-12-17T16:37:08.232482",
          "exception": false,
          "start_time": "2024-12-17T16:37:08.208725",
          "status": "completed"
        },
        "tags": [],
        "id": "23972ef0"
      },
      "source": [
        "### Checking data's structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71747b23",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-17T16:37:08.276855Z",
          "iopub.status.busy": "2024-12-17T16:37:08.276562Z",
          "iopub.status.idle": "2024-12-17T16:37:08.290692Z",
          "shell.execute_reply": "2024-12-17T16:37:08.289930Z"
        },
        "papermill": {
          "duration": 0.037967,
          "end_time": "2024-12-17T16:37:08.292256",
          "exception": false,
          "start_time": "2024-12-17T16:37:08.254289",
          "status": "completed"
        },
        "tags": [],
        "id": "71747b23"
      },
      "outputs": [],
      "source": [
        "dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c01a895d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-17T16:37:08.337726Z",
          "iopub.status.busy": "2024-12-17T16:37:08.337262Z",
          "iopub.status.idle": "2024-12-17T16:37:08.366713Z",
          "shell.execute_reply": "2024-12-17T16:37:08.365743Z"
        },
        "papermill": {
          "duration": 0.054349,
          "end_time": "2024-12-17T16:37:08.368566",
          "exception": false,
          "start_time": "2024-12-17T16:37:08.314217",
          "status": "completed"
        },
        "tags": [],
        "id": "c01a895d"
      },
      "outputs": [],
      "source": [
        "train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36b7f936",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-17T16:37:08.413613Z",
          "iopub.status.busy": "2024-12-17T16:37:08.413360Z",
          "iopub.status.idle": "2024-12-17T16:37:08.423628Z",
          "shell.execute_reply": "2024-12-17T16:37:08.422799Z"
        },
        "papermill": {
          "duration": 0.03457,
          "end_time": "2024-12-17T16:37:08.425314",
          "exception": false,
          "start_time": "2024-12-17T16:37:08.390744",
          "status": "completed"
        },
        "tags": [],
        "id": "36b7f936"
      },
      "outputs": [],
      "source": [
        "test.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "647ed368",
      "metadata": {
        "papermill": {
          "duration": 0.02213,
          "end_time": "2024-12-17T16:37:08.470002",
          "exception": false,
          "start_time": "2024-12-17T16:37:08.447872",
          "status": "completed"
        },
        "tags": [],
        "id": "647ed368"
      },
      "source": [
        "# 3.Preprocess data\n",
        "We perform preprocessing for both CSV data and time series data. Specifically, as follows:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e87da0b0",
      "metadata": {
        "papermill": {
          "duration": 0.023678,
          "end_time": "2024-12-17T16:37:08.515658",
          "exception": false,
          "start_time": "2024-12-17T16:37:08.491980",
          "status": "completed"
        },
        "tags": [],
        "id": "e87da0b0"
      },
      "source": [
        "## 3.1 Preprocess csv\n",
        "We perform some techniques as mentioned in the presentation to preprocess CSV data, such as:\n",
        "* We remove columns that exist in the training data but not in the testing data.\n",
        "* We fill all missing data (Nan value).\n",
        "* We remove columns ('season' features) with string values.\n",
        "* In addition, we generate new important features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76d3403a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-17T16:37:08.561146Z",
          "iopub.status.busy": "2024-12-17T16:37:08.560890Z",
          "iopub.status.idle": "2024-12-17T16:37:11.205721Z",
          "shell.execute_reply": "2024-12-17T16:37:11.204937Z"
        },
        "papermill": {
          "duration": 2.67481,
          "end_time": "2024-12-17T16:37:11.212780",
          "exception": false,
          "start_time": "2024-12-17T16:37:08.537970",
          "status": "completed"
        },
        "tags": [],
        "id": "76d3403a"
      },
      "outputs": [],
      "source": [
        "# Check the data status in the train set\n",
        "msno.bar(train.iloc[:, :train.shape[1]], sort='ascending')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "215101eb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-17T16:37:11.277663Z",
          "iopub.status.busy": "2024-12-17T16:37:11.277358Z",
          "iopub.status.idle": "2024-12-17T16:37:13.189516Z",
          "shell.execute_reply": "2024-12-17T16:37:13.188690Z"
        },
        "papermill": {
          "duration": 1.949771,
          "end_time": "2024-12-17T16:37:13.194297",
          "exception": false,
          "start_time": "2024-12-17T16:37:11.244526",
          "status": "completed"
        },
        "tags": [],
        "id": "215101eb"
      },
      "outputs": [],
      "source": [
        "# Check the data status in the test set\n",
        "msno.bar(test.iloc[:, :test.shape[1]], sort='ascending')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cca2999f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-17T16:37:13.267478Z",
          "iopub.status.busy": "2024-12-17T16:37:13.267170Z",
          "iopub.status.idle": "2024-12-17T16:37:13.272781Z",
          "shell.execute_reply": "2024-12-17T16:37:13.271970Z"
        },
        "papermill": {
          "duration": 0.042765,
          "end_time": "2024-12-17T16:37:13.274338",
          "exception": false,
          "start_time": "2024-12-17T16:37:13.231573",
          "status": "completed"
        },
        "tags": [],
        "id": "cca2999f"
      },
      "outputs": [],
      "source": [
        "# Check the extra columns in the train set that are not in the test set\n",
        "different_columns = set(train) - set(test)\n",
        "different_columns # The 'sii' column is the label and should be kept"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80cf9497",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-17T16:37:13.342360Z",
          "iopub.status.busy": "2024-12-17T16:37:13.342103Z",
          "iopub.status.idle": "2024-12-17T16:37:13.347492Z",
          "shell.execute_reply": "2024-12-17T16:37:13.346683Z"
        },
        "papermill": {
          "duration": 0.0413,
          "end_time": "2024-12-17T16:37:13.349110",
          "exception": false,
          "start_time": "2024-12-17T16:37:13.307810",
          "status": "completed"
        },
        "tags": [],
        "id": "80cf9497"
      },
      "outputs": [],
      "source": [
        "common_columns = train.columns.intersection(test.columns) # Get the common columns between train and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6d91627",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-17T16:37:13.416466Z",
          "iopub.status.busy": "2024-12-17T16:37:13.416027Z",
          "iopub.status.idle": "2024-12-17T16:37:13.422596Z",
          "shell.execute_reply": "2024-12-17T16:37:13.421769Z"
        },
        "papermill": {
          "duration": 0.042047,
          "end_time": "2024-12-17T16:37:13.424083",
          "exception": false,
          "start_time": "2024-12-17T16:37:13.382036",
          "status": "completed"
        },
        "tags": [],
        "id": "f6d91627"
      },
      "outputs": [],
      "source": [
        "# Create data containing only the columns from the test set\n",
        "train_df = train[common_columns]\n",
        "\n",
        "# Reattach the label\n",
        "train_df['sii'] = train['sii']\n",
        "train = train_df\n",
        "\n",
        "test = test[common_columns]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ca0c346",
      "metadata": {
        "papermill": {
          "duration": 0.033596,
          "end_time": "2024-12-17T16:37:13.490627",
          "exception": false,
          "start_time": "2024-12-17T16:37:13.457031",
          "status": "completed"
        },
        "tags": [],
        "id": "0ca0c346"
      },
      "source": [
        "### Encode Season\n",
        "By using the season_encode helper function - which converts string values ​​to categorical (int) form, we enable decision tree models to learn string features like this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71d04aa2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-17T16:37:13.558725Z",
          "iopub.status.busy": "2024-12-17T16:37:13.558195Z",
          "iopub.status.idle": "2024-12-17T16:37:13.563465Z",
          "shell.execute_reply": "2024-12-17T16:37:13.562801Z"
        },
        "papermill": {
          "duration": 0.041192,
          "end_time": "2024-12-17T16:37:13.565078",
          "exception": false,
          "start_time": "2024-12-17T16:37:13.523886",
          "status": "completed"
        },
        "tags": [],
        "id": "71d04aa2"
      },
      "outputs": [],
      "source": [
        "def season_encode(df, kill_season=False):\n",
        "    \"\"\"\n",
        "    Encodes seasonal data in a DataFrame or removes seasonal columns based on input parameters.\n",
        "\n",
        "    Parameters:\n",
        "        df (pd.DataFrame): The input DataFrame containing the data to process.\n",
        "        kill_season (bool, optional):\n",
        "            - If `True`, removes all columns with \"Season\" in their names.\n",
        "            - If `False`, encodes string columns with season-related data using a predefined mapping.\n",
        "            Default is `False`.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame:\n",
        "            - If `kill_season=True`, a DataFrame with \"Season\" columns removed.\n",
        "            - If `kill_season=False`, a DataFrame with seasonal data encoded and the `id` column preserved.\n",
        "\n",
        "    Mapping:\n",
        "        The seasonal strings are encoded as follows:\n",
        "        - 'Spring' -> 1\n",
        "        - 'Summer' -> 2\n",
        "        - 'Fall'   -> 3\n",
        "        - 'Winter' -> 4\n",
        "        - NaN      -> 0\n",
        "    \"\"\"\n",
        "    if kill_season:\n",
        "        season_cols = [col for col in df.columns if 'Season' in col]\n",
        "        df_ = df.drop(season_cols, axis=1)\n",
        "        return df_\n",
        "\n",
        "    df_no_id = df.drop(columns='id')\n",
        "    string_columns = df_no_id.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "    season_encode_map = {\n",
        "        'Spring': 1,\n",
        "        'Summer': 2,\n",
        "        'Fall': 3,\n",
        "        'Winter': 4,\n",
        "        np.nan: 0\n",
        "    }\n",
        "\n",
        "    # Apply mapping for all string format columns\n",
        "    df_no_id[string_columns] = df_no_id[string_columns].apply(lambda col: col.map(season_encode_map))\n",
        "    df_no_id['id'] = df['id']\n",
        "    return df_no_id"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09622632",
      "metadata": {
        "papermill": {
          "duration": 0.032912,
          "end_time": "2024-12-17T16:37:13.632598",
          "exception": false,
          "start_time": "2024-12-17T16:37:13.599686",
          "status": "completed"
        },
        "tags": [],
        "id": "09622632"
      },
      "source": [
        "### Feature Engineering\n",
        "Based on strong correlations between features in the data, thereby creating features that are more meaningful to prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "766dace5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-17T16:37:13.700425Z",
          "iopub.status.busy": "2024-12-17T16:37:13.700143Z",
          "iopub.status.idle": "2024-12-17T16:37:13.706891Z",
          "shell.execute_reply": "2024-12-17T16:37:13.706089Z"
        },
        "papermill": {
          "duration": 0.04296,
          "end_time": "2024-12-17T16:37:13.708446",
          "exception": false,
          "start_time": "2024-12-17T16:37:13.665486",
          "status": "completed"
        },
        "tags": [],
        "id": "766dace5"
      },
      "outputs": [],
      "source": [
        "def feature_engineering(df_):\n",
        "    \"\"\"\n",
        "    Performs feature engineering on a given DataFrame by creating new derived features\n",
        "    related to physical health, body composition, and internet usage.\n",
        "\n",
        "    Parameters:\n",
        "        df_ (pd.DataFrame): The input DataFrame containing the necessary columns for feature calculations.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A new DataFrame with the original columns and additional engineered features.\n",
        "    \"\"\"\n",
        "\n",
        "    df = df_.copy()\n",
        "    # Product of BMI and Age\n",
        "    df['BMI_Age'] = df['Physical-BMI'] * df['Basic_Demos-Age']\n",
        "    # Product of daily internet hours and Age\n",
        "    df['Internet_Hours_Age'] = df['PreInt_EduHx-computerinternet_hoursday'] * df['Basic_Demos-Age']\n",
        "    # Product of BMI and daily internet hours\n",
        "    df['BMI_Internet_Hours'] = df['Physical-BMI'] * df['PreInt_EduHx-computerinternet_hoursday']\n",
        "\n",
        "    # Ratio of body fat percentage to BMI\n",
        "    df['BFP_BMI'] = df['BIA-BIA_Fat'] / df['BIA-BIA_BMI']\n",
        "    # Ratio of fat-free mass index to body fat percentage\n",
        "    df['FFMI_BFP'] = df['BIA-BIA_FFMI'] / df['BIA-BIA_Fat']\n",
        "    # Ratio of fat mass index to body fat percentage\n",
        "    df['FMI_BFP'] = df['BIA-BIA_FMI'] / df['BIA-BIA_Fat']\n",
        "    # Ratio of lean soft tissue to total body water\n",
        "    df['LST_TBW'] = df['BIA-BIA_LST'] / df['BIA-BIA_TBW']\n",
        "    # Product of body fat percentage and basal metabolic rate\n",
        "    df['BFP_BMR'] = df['BIA-BIA_Fat'] * df['BIA-BIA_BMR']\n",
        "    # Product of body fat percentage and daily energy expenditure\n",
        "    df['BFP_DEE'] = df['BIA-BIA_Fat'] * df['BIA-BIA_DEE']\n",
        "    # Ratio of basal metabolic rate to weight\n",
        "    df['BMR_Weight'] = df['BIA-BIA_BMR'] / df['Physical-Weight']\n",
        "    # Ratio of daily energy expenditure to weight\n",
        "    df['DEE_Weight'] = df['BIA-BIA_DEE'] / df['Physical-Weight']\n",
        "    # Ratio of skeletal muscle mass to height\n",
        "    df['SMM_Height'] = df['BIA-BIA_SMM'] / df['Physical-Height']\n",
        "    # Ratio of skeletal muscle mass to fat mass index\n",
        "    df['Muscle_to_Fat'] = df['BIA-BIA_SMM'] / df['BIA-BIA_FMI']\n",
        "    # Ratio of total body water to weight\n",
        "    df['Hydration_Status'] = df['BIA-BIA_TBW'] / df['Physical-Weight']\n",
        "\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d1c639a",
      "metadata": {
        "papermill": {
          "duration": 0.032971,
          "end_time": "2024-12-17T16:37:13.774779",
          "exception": false,
          "start_time": "2024-12-17T16:37:13.741808",
          "status": "completed"
        },
        "tags": [],
        "id": "3d1c639a"
      },
      "source": [
        "## 3.2 Preprocess parquet (time series)\n",
        "In this section, we will learn how to extract and process time series data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43485f79",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-17T16:37:13.841709Z",
          "iopub.status.busy": "2024-12-17T16:37:13.841441Z",
          "iopub.status.idle": "2024-12-17T16:37:13.845650Z",
          "shell.execute_reply": "2024-12-17T16:37:13.844932Z"
        },
        "papermill": {
          "duration": 0.039764,
          "end_time": "2024-12-17T16:37:13.847391",
          "exception": false,
          "start_time": "2024-12-17T16:37:13.807627",
          "status": "completed"
        },
        "tags": [],
        "id": "43485f79"
      },
      "outputs": [],
      "source": [
        "# Checking time series data's size\n",
        "print(f\"2 tập cùng số features: {train_ts.shape[1] == test_ts.shape[1]}\")\n",
        "# True => All fetures exist in both train and test data\n",
        "print(f\"Số features: {train_ts.shape[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0991ae5",
      "metadata": {
        "papermill": {
          "duration": 0.032541,
          "end_time": "2024-12-17T16:37:13.912882",
          "exception": false,
          "start_time": "2024-12-17T16:37:13.880341",
          "status": "completed"
        },
        "tags": [],
        "id": "d0991ae5"
      },
      "source": [
        "### Helper function auto encoder\n",
        "This function helps us automatically extract features of time series data using the AutoEncoder architecture.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "949bbfab",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-17T16:37:13.979645Z",
          "iopub.status.busy": "2024-12-17T16:37:13.979370Z",
          "iopub.status.idle": "2024-12-17T16:37:13.984712Z",
          "shell.execute_reply": "2024-12-17T16:37:13.984022Z"
        },
        "papermill": {
          "duration": 0.040656,
          "end_time": "2024-12-17T16:37:13.986268",
          "exception": false,
          "start_time": "2024-12-17T16:37:13.945612",
          "status": "completed"
        },
        "tags": [],
        "id": "949bbfab"
      },
      "outputs": [],
      "source": [
        "class AutoEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    A neural network-based autoencoder for dimensionality reduction and feature extraction.\n",
        "\n",
        "    The autoencoder consists of an encoder and a decoder:\n",
        "    - The encoder compresses the input data into a lower-dimensional latent space.\n",
        "    - The decoder reconstructs the input data from the compressed representation.\n",
        "\n",
        "    Attributes:\n",
        "        encoder (nn.Sequential): A feedforward neural network that maps input data\n",
        "            to a lower-dimensional encoding using a series of linear layers and ReLU activations.\n",
        "        decoder (nn.Sequential): A feedforward neural network that reconstructs the input data\n",
        "            from the encoded representation using a series of linear layers and ReLU/Sigmoid activations.\n",
        "\n",
        "    Parameters:\n",
        "        input_dim (int): The dimensionality of the input data.\n",
        "        encoding_dim (int): The dimensionality of the latent space (encoded representation).\n",
        "\n",
        "    Methods:\n",
        "        forward(x):\n",
        "            Passes the input data through the encoder and decoder to produce reconstructed output.\n",
        "\n",
        "            Parameters:\n",
        "                x (torch.Tensor): The input data tensor with shape (batch_size, input_dim).\n",
        "\n",
        "            Returns:\n",
        "                torch.Tensor: The reconstructed data tensor with shape (batch_size, input_dim).\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, encoding_dim):\n",
        "        super(AutoEncoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, encoding_dim*3),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(encoding_dim*3, encoding_dim*2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(encoding_dim*2, encoding_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(encoding_dim, input_dim*2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(input_dim*2, input_dim*3),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(input_dim*3, input_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b80d9e35",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-17T16:37:14.054207Z",
          "iopub.status.busy": "2024-12-17T16:37:14.053959Z",
          "iopub.status.idle": "2024-12-17T16:37:14.060325Z",
          "shell.execute_reply": "2024-12-17T16:37:14.059610Z"
        },
        "papermill": {
          "duration": 0.042143,
          "end_time": "2024-12-17T16:37:14.061848",
          "exception": false,
          "start_time": "2024-12-17T16:37:14.019705",
          "status": "completed"
        },
        "tags": [],
        "id": "b80d9e35"
      },
      "outputs": [],
      "source": [
        "def perform_autoencoder(df, encoding_dim=50, epochs=50, batch_size=32):\n",
        "    \"\"\"\n",
        "    Performs dimensionality reduction using an autoencoder on the given DataFrame.\n",
        "\n",
        "    This function scales the input data, trains an autoencoder to compress the data\n",
        "    into a lower-dimensional space, and returns the encoded representation.\n",
        "\n",
        "    Parameters:\n",
        "        df (pd.DataFrame): The input data to be encoded.\n",
        "        encoding_dim (int, optional): The dimensionality of the latent space (encoded representation). Default is 50.\n",
        "        epochs (int, optional): The number of training epochs. Default is 50.\n",
        "        batch_size (int, optional): The size of each mini-batch during training. Default is 32.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing the encoded representation with column names `Enc_1, Enc_2, ...`.\n",
        "    \"\"\"\n",
        "\n",
        "    # Scale the input data to standardize features\n",
        "    scaler = StandardScaler()\n",
        "    df_scaled = scaler.fit_transform(df)\n",
        "\n",
        "    # Convert scaled data into a PyTorch tensor\n",
        "    data_tensor = torch.FloatTensor(df_scaled)\n",
        "\n",
        "    # Initialize the autoencoder with input dimensions and encoding dimensions\n",
        "    input_dim = data_tensor.shape[1]\n",
        "    autoencoder = AutoEncoder(input_dim, encoding_dim)\n",
        "\n",
        "    # Define the loss function (Mean Squared Error) and the optimizer (Adam)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(autoencoder.parameters())\n",
        "\n",
        "    # Train the autoencoder model\n",
        "    for epoch in range(epochs):\n",
        "        for i in range(0, len(data_tensor), batch_size):\n",
        "            # Get the current mini-batch\n",
        "            batch = data_tensor[i : i + batch_size]\n",
        "            optimizer.zero_grad()  # Reset gradients\n",
        "            reconstructed = autoencoder(batch)  # Forward pass\n",
        "            loss = criterion(reconstructed, batch)  # Compute reconstruction loss\n",
        "            loss.backward()  # Backward pass\n",
        "            optimizer.step()  # Update weights\n",
        "\n",
        "        # Print the loss every 10 epochs\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}]')\n",
        "\n",
        "    # Encode the data using the trained encoder\n",
        "    with torch.no_grad():\n",
        "        encoded_data = autoencoder.encoder(data_tensor).numpy()\n",
        "\n",
        "    # Create a DataFrame for the encoded data\n",
        "    df_encoded = pd.DataFrame(encoded_data, columns=[f'Enc_{i + 1}' for i in range(encoded_data.shape[1])])\n",
        "\n",
        "    return df_encoded\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8850b82d",
      "metadata": {
        "papermill": {
          "duration": 0.034119,
          "end_time": "2024-12-17T16:37:14.128996",
          "exception": false,
          "start_time": "2024-12-17T16:37:14.094877",
          "status": "completed"
        },
        "tags": [],
        "id": "8850b82d"
      },
      "source": [
        "### Encode data\n",
        "Perform data encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "255f50ab",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-17T16:37:14.197923Z",
          "iopub.status.busy": "2024-12-17T16:37:14.197615Z",
          "iopub.status.idle": "2024-12-17T16:37:26.733845Z",
          "shell.execute_reply": "2024-12-17T16:37:26.732825Z"
        },
        "papermill": {
          "duration": 12.573748,
          "end_time": "2024-12-17T16:37:26.735586",
          "exception": false,
          "start_time": "2024-12-17T16:37:14.161838",
          "status": "completed"
        },
        "tags": [],
        "id": "255f50ab"
      },
      "outputs": [],
      "source": [
        "df_train = train_ts.drop('id', axis=1)\n",
        "df_test = test_ts.drop('id', axis=1)\n",
        "\n",
        "print(\"Train encode\")\n",
        "train_ts_encoded = perform_autoencoder(df_train, encoding_dim=60, epochs=100, batch_size=32)\n",
        "print(\"Test encode\")\n",
        "test_ts_encoded = perform_autoencoder(df_test, encoding_dim=60, epochs=100, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1097985",
      "metadata": {
        "papermill": {
          "duration": 0.034149,
          "end_time": "2024-12-17T16:37:26.804551",
          "exception": false,
          "start_time": "2024-12-17T16:37:26.770402",
          "status": "completed"
        },
        "tags": [],
        "id": "f1097985"
      },
      "source": [
        "Loss ko giảm, ko cần nhiều epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f4a8aeb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-17T16:37:26.874390Z",
          "iopub.status.busy": "2024-12-17T16:37:26.873586Z",
          "iopub.status.idle": "2024-12-17T16:37:26.879519Z",
          "shell.execute_reply": "2024-12-17T16:37:26.878661Z"
        },
        "papermill": {
          "duration": 0.042324,
          "end_time": "2024-12-17T16:37:26.881190",
          "exception": false,
          "start_time": "2024-12-17T16:37:26.838866",
          "status": "completed"
        },
        "tags": [],
        "id": "7f4a8aeb"
      },
      "outputs": [],
      "source": [
        "# Reattach id column\n",
        "train_ts_encoded[\"id\"]=train_ts[\"id\"]\n",
        "test_ts_encoded['id']=test_ts[\"id\"]\n",
        "\n",
        "# Get all time series columns\n",
        "time_series_cols = train_ts_encoded.columns.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5737f87",
      "metadata": {
        "papermill": {
          "duration": 0.033742,
          "end_time": "2024-12-17T16:37:26.949014",
          "exception": false,
          "start_time": "2024-12-17T16:37:26.915272",
          "status": "completed"
        },
        "tags": [],
        "id": "d5737f87"
      },
      "source": [
        "## 3.3 Combine data\n",
        "We perform the concatenation of the encoded string data with the original data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa812352",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-17T16:37:27.018184Z",
          "iopub.status.busy": "2024-12-17T16:37:27.017147Z",
          "iopub.status.idle": "2024-12-17T16:37:27.053398Z",
          "shell.execute_reply": "2024-12-17T16:37:27.052712Z"
        },
        "papermill": {
          "duration": 0.072599,
          "end_time": "2024-12-17T16:37:27.055220",
          "exception": false,
          "start_time": "2024-12-17T16:37:26.982621",
          "status": "completed"
        },
        "tags": [],
        "id": "fa812352"
      },
      "outputs": [],
      "source": [
        "# Drop \"season\" columns\n",
        "train_has_season = season_encode(train, kill_season=True)\n",
        "test_has_season = season_encode(test, kill_season=True)\n",
        "\n",
        "# Merge data on \"id\" column\n",
        "train_combine = pd.merge(train_has_season, train_ts_encoded, how='left', on='id')\n",
        "test_combine = pd.merge(test_has_season, test_ts_encoded, how='left', on='id')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00afb5cd",
      "metadata": {
        "papermill": {
          "duration": 0.033637,
          "end_time": "2024-12-17T16:37:27.123480",
          "exception": false,
          "start_time": "2024-12-17T16:37:27.089843",
          "status": "completed"
        },
        "tags": [],
        "id": "00afb5cd"
      },
      "source": [
        "#### Fill nan\n",
        "Fill NaN values by using KNNImputer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28ce3534",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-17T16:37:27.195961Z",
          "iopub.status.busy": "2024-12-17T16:37:27.195605Z",
          "iopub.status.idle": "2024-12-17T16:37:27.204009Z",
          "shell.execute_reply": "2024-12-17T16:37:27.203059Z"
        },
        "papermill": {
          "duration": 0.046928,
          "end_time": "2024-12-17T16:37:27.205738",
          "exception": false,
          "start_time": "2024-12-17T16:37:27.158810",
          "status": "completed"
        },
        "tags": [],
        "id": "28ce3534"
      },
      "outputs": [],
      "source": [
        "imputer = KNNImputer(n_neighbors=6)\n",
        "\n",
        "train = train_combine\n",
        "test = test_combine\n",
        "\n",
        "numeric_cols_train = train.select_dtypes(include=['int32', 'int64', 'float64']).columns\n",
        "numeric_cols_test = test.select_dtypes(include=['int32', 'int64', 'float64']).columns\n",
        "\n",
        "imputed_train_data = imputer.fit_transform(train[numeric_cols_train])\n",
        "imputed_test_data = imputer.fit_transform(test[numeric_cols_test])\n",
        "\n",
        "train_imputed = pd.DataFrame(imputed_train_data, columns=numeric_cols_train)\n",
        "test_imputed = pd.DataFrame(imputed_test_data, columns=numeric_cols_test)\n",
        "\n",
        "train_imputed['sii'] = train_imputed['sii'].round().astype(int)\n",
        "for col in train.columns:\n",
        "    if col not in numeric_cols_train:\n",
        "        train_imputed[col] = train[col]\n",
        "\n",
        "for col in test.columns:\n",
        "    if col not in numeric_cols_test:\n",
        "        test_imputed[col] = test[col]\n",
        "\n",
        "train = train_imputed\n",
        "test = test_imputed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcced143",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-17T16:37:27.275807Z",
          "iopub.status.busy": "2024-12-17T16:37:27.275199Z",
          "iopub.status.idle": "2024-12-17T16:37:27.291262Z",
          "shell.execute_reply": "2024-12-17T16:37:27.290526Z"
        },
        "papermill": {
          "duration": 0.052016,
          "end_time": "2024-12-17T16:37:27.292884",
          "exception": false,
          "start_time": "2024-12-17T16:37:27.240868",
          "status": "completed"
        },
        "tags": [],
        "id": "bcced143"
      },
      "outputs": [],
      "source": [
        "## Process data after fill / drop \"sii\" Nan values\n",
        "train_combine = feature_engineering(train_combine)\n",
        "test_combine = feature_engineering(test_combine)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "470ed0bc",
      "metadata": {
        "papermill": {
          "duration": 0.034402,
          "end_time": "2024-12-17T16:37:27.361080",
          "exception": false,
          "start_time": "2024-12-17T16:37:27.326678",
          "status": "completed"
        },
        "tags": [],
        "id": "470ed0bc"
      },
      "source": [
        "## 3.4 Select feature\n",
        "We perform robust feature selection, based on the correlation matrix. Additionally, we merge the processed time series data with the original data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eee8f6d6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-17T16:37:27.430779Z",
          "iopub.status.busy": "2024-12-17T16:37:27.430432Z",
          "iopub.status.idle": "2024-12-17T16:37:27.439852Z",
          "shell.execute_reply": "2024-12-17T16:37:27.439078Z"
        },
        "papermill": {
          "duration": 0.046624,
          "end_time": "2024-12-17T16:37:27.441695",
          "exception": false,
          "start_time": "2024-12-17T16:37:27.395071",
          "status": "completed"
        },
        "tags": [],
        "id": "eee8f6d6"
      },
      "outputs": [],
      "source": [
        "# Selecting feature (Drop features, which have >70% Nan values)\n",
        "train_featuresCols = ['Basic_Demos-Enroll_Season', 'Basic_Demos-Age', 'Basic_Demos-Sex',\n",
        "                'CGAS-Season', 'CGAS-CGAS_Score', 'Physical-Season', 'Physical-BMI',\n",
        "                'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference',\n",
        "                'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP',\n",
        "                'Fitness_Endurance-Season', 'Fitness_Endurance-Max_Stage',\n",
        "                'Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec',\n",
        "                'FGC-Season', 'FGC-FGC_CU', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND',\n",
        "                'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone', 'FGC-FGC_PU',\n",
        "                'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR',\n",
        "                'FGC-FGC_SRR_Zone', 'FGC-FGC_TL', 'FGC-FGC_TL_Zone', 'BIA-Season',\n",
        "                'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI',\n",
        "                'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM',\n",
        "                'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat', 'BIA-BIA_Frame_num',\n",
        "                'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM',\n",
        "                'BIA-BIA_TBW', 'PAQ_A-Season', 'PAQ_A-PAQ_A_Total', 'PAQ_C-Season',\n",
        "                'PAQ_C-PAQ_C_Total', 'SDS-Season', 'SDS-SDS_Total_Raw',\n",
        "                'SDS-SDS_Total_T', 'PreInt_EduHx-Season',\n",
        "                'PreInt_EduHx-computerinternet_hoursday', 'sii']\n",
        "\n",
        "# Merge features from csv and time series features\n",
        "train_featuresCols += time_series_cols\n",
        "\n",
        "test_featuresCols = ['Basic_Demos-Enroll_Season', 'Basic_Demos-Age', 'Basic_Demos-Sex',\n",
        "                'CGAS-Season', 'CGAS-CGAS_Score', 'Physical-Season', 'Physical-BMI',\n",
        "                'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference',\n",
        "                'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP',\n",
        "                'Fitness_Endurance-Season', 'Fitness_Endurance-Max_Stage',\n",
        "                'Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec',\n",
        "                'FGC-Season', 'FGC-FGC_CU', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND',\n",
        "                'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone', 'FGC-FGC_PU',\n",
        "                'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR',\n",
        "                'FGC-FGC_SRR_Zone', 'FGC-FGC_TL', 'FGC-FGC_TL_Zone', 'BIA-Season',\n",
        "                'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI',\n",
        "                'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM',\n",
        "                'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat', 'BIA-BIA_Frame_num',\n",
        "                'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM',\n",
        "                'BIA-BIA_TBW', 'PAQ_A-Season', 'PAQ_A-PAQ_A_Total', 'PAQ_C-Season',\n",
        "                'PAQ_C-PAQ_C_Total', 'SDS-Season', 'SDS-SDS_Total_Raw',\n",
        "                'SDS-SDS_Total_T', 'PreInt_EduHx-Season',\n",
        "                'PreInt_EduHx-computerinternet_hoursday']\n",
        "\n",
        "test_featuresCols += time_series_cols\n",
        "\n",
        "train_combine = train_combine[train_featuresCols]\n",
        "test_combine = test_combine[test_featuresCols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2853f7c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-17T16:37:27.551482Z",
          "iopub.status.busy": "2024-12-17T16:37:27.551154Z",
          "iopub.status.idle": "2024-12-17T16:37:27.558151Z",
          "shell.execute_reply": "2024-12-17T16:37:27.557215Z"
        },
        "papermill": {
          "duration": 0.046738,
          "end_time": "2024-12-17T16:37:27.559781",
          "exception": false,
          "start_time": "2024-12-17T16:37:27.513043",
          "status": "completed"
        },
        "tags": [],
        "id": "e2853f7c"
      },
      "outputs": [],
      "source": [
        "## Remove \"id\" column in both sets\n",
        "train_combine.drop(columns=['id'], inplace=True)\n",
        "test_combine.drop(columns=['id'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e25fd5d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-17T16:37:27.632230Z",
          "iopub.status.busy": "2024-12-17T16:37:27.631627Z",
          "iopub.status.idle": "2024-12-17T16:37:27.641590Z",
          "shell.execute_reply": "2024-12-17T16:37:27.640785Z"
        },
        "papermill": {
          "duration": 0.048002,
          "end_time": "2024-12-17T16:37:27.643163",
          "exception": false,
          "start_time": "2024-12-17T16:37:27.595161",
          "status": "completed"
        },
        "tags": [],
        "id": "2e25fd5d"
      },
      "outputs": [],
      "source": [
        "# Presentating distribution of label after resolve NaN\n",
        "train_combine['sii'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3692e78",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-17T16:37:27.713684Z",
          "iopub.status.busy": "2024-12-17T16:37:27.712983Z",
          "iopub.status.idle": "2024-12-17T16:37:27.719730Z",
          "shell.execute_reply": "2024-12-17T16:37:27.718871Z"
        },
        "papermill": {
          "duration": 0.043649,
          "end_time": "2024-12-17T16:37:27.721288",
          "exception": false,
          "start_time": "2024-12-17T16:37:27.677639",
          "status": "completed"
        },
        "tags": [],
        "id": "e3692e78"
      },
      "outputs": [],
      "source": [
        "# Presentating distribution of label before resolve NaN\n",
        "train['sii'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b06b0422",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-17T16:37:27.791317Z",
          "iopub.status.busy": "2024-12-17T16:37:27.790626Z",
          "iopub.status.idle": "2024-12-17T16:37:27.796637Z",
          "shell.execute_reply": "2024-12-17T16:37:27.796017Z"
        },
        "papermill": {
          "duration": 0.043114,
          "end_time": "2024-12-17T16:37:27.798479",
          "exception": false,
          "start_time": "2024-12-17T16:37:27.755365",
          "status": "completed"
        },
        "tags": [],
        "id": "b06b0422"
      },
      "outputs": [],
      "source": [
        "# Replacing minus infinity or infinity values to Nan values\n",
        "train_combine.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "test_combine.replace([np.inf, -np.inf], np.nan, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "790ee794",
      "metadata": {
        "papermill": {
          "duration": 0.034143,
          "end_time": "2024-12-17T16:37:27.867832",
          "exception": false,
          "start_time": "2024-12-17T16:37:27.833689",
          "status": "completed"
        },
        "tags": [],
        "id": "790ee794"
      },
      "source": [
        "# 4. Training model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21e26349",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-17T16:37:27.937433Z",
          "iopub.status.busy": "2024-12-17T16:37:27.936651Z",
          "iopub.status.idle": "2024-12-17T16:37:27.943583Z",
          "shell.execute_reply": "2024-12-17T16:37:27.942767Z"
        },
        "papermill": {
          "duration": 0.043791,
          "end_time": "2024-12-17T16:37:27.945265",
          "exception": false,
          "start_time": "2024-12-17T16:37:27.901474",
          "status": "completed"
        },
        "tags": [],
        "id": "21e26349"
      },
      "outputs": [],
      "source": [
        "## Hyperparameters\n",
        "N_SPLITS = 5\n",
        "SEED = 42\n",
        "\n",
        "# Parameter for 3 model\n",
        "LightGBM_Params = {\n",
        "    'random_state': SEED,\n",
        "    'verbose':-1,\n",
        "    'n_estimators': 200,\n",
        "    'learning_rate': 0.046,\n",
        "    'max_depth': 12,\n",
        "    'num_leaves': 478,\n",
        "    'min_data_in_leaf': 13,\n",
        "    'feature_fraction': 0.893,\n",
        "    'bagging_fraction': 0.784,\n",
        "    'bagging_freq': 4,\n",
        "    'lambda_l1': 10,\n",
        "    'lambda_l2': 0.01,\n",
        "    'device': 'cpu',\n",
        "}\n",
        "\n",
        "\n",
        "XGB_Params = {\n",
        "    'learning_rate': 0.05,\n",
        "    'max_depth': 6,\n",
        "    'n_estimators': 200,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'reg_alpha': 1,\n",
        "    'reg_lambda': 5,\n",
        "    'random_state': SEED,\n",
        "    'tree_method': 'gpu_hist',\n",
        "}\n",
        "\n",
        "\n",
        "CatBoost_Params = {\n",
        "    'learning_rate': 0.05,\n",
        "    'depth': 6,\n",
        "    'iterations': 200,\n",
        "    'random_seed': 42,\n",
        "    'verbose': 0,\n",
        "    'l2_leaf_reg': 10,\n",
        "    'task_type': 'GPU'\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb9edceb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-17T16:37:28.015120Z",
          "iopub.status.busy": "2024-12-17T16:37:28.014830Z",
          "iopub.status.idle": "2024-12-17T16:37:28.019629Z",
          "shell.execute_reply": "2024-12-17T16:37:28.018886Z"
        },
        "papermill": {
          "duration": 0.041555,
          "end_time": "2024-12-17T16:37:28.021205",
          "exception": false,
          "start_time": "2024-12-17T16:37:27.979650",
          "status": "completed"
        },
        "tags": [],
        "id": "cb9edceb"
      },
      "outputs": [],
      "source": [
        "## Useful function\n",
        "def quadratic_weighted_kappa(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculates the quadratic weighted kappa between the true labels and predicted labels.\n",
        "\n",
        "    Quadratic weighted kappa is a metric that measures the agreement between two categorical variables\n",
        "    while penalizing disagreements based on the magnitude of the difference.\n",
        "\n",
        "    Parameters:\n",
        "        y_true (array-like): The true labels.\n",
        "        y_pred (array-like): The predicted labels.\n",
        "\n",
        "    Returns:\n",
        "        float: The quadratic weighted kappa score between 0 (no agreement) and 1 (perfect agreement).\n",
        "    \"\"\"\n",
        "    return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
        "\n",
        "\n",
        "def threshold_Rounder(oof_non_rounded, thresholds):\n",
        "    \"\"\"\n",
        "    Rounds the continuous predictions to discrete classes based on specified thresholds.\n",
        "\n",
        "    This function takes a continuous set of predictions and rounds them to the nearest class\n",
        "    by comparing them against predefined threshold values.\n",
        "\n",
        "    Parameters:\n",
        "        oof_non_rounded (array-like): The continuous predictions to be rounded.\n",
        "        thresholds (list or array-like): The threshold values for classifying the predictions.\n",
        "            The thresholds should define the boundaries between classes.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: An array of rounded predictions (class labels).\n",
        "    \"\"\"\n",
        "    return np.where(oof_non_rounded < thresholds[0], 0,\n",
        "                    np.where(oof_non_rounded < thresholds[1], 1,\n",
        "                             np.where(oof_non_rounded < thresholds[2], 2, 3)))\n",
        "\n",
        "\n",
        "def evaluate_predictions(thresholds, y_true, oof_non_rounded):\n",
        "    \"\"\"\n",
        "    Evaluates the performance of predictions by rounding them based on thresholds and calculating\n",
        "    the negative quadratic weighted kappa score.\n",
        "\n",
        "    This function rounds the predictions using the `threshold_Rounder` function and then calculates\n",
        "    the quadratic weighted kappa between the rounded predictions and the true labels.\n",
        "\n",
        "    Parameters:\n",
        "        thresholds (list or array-like): The threshold values for classifying the predictions.\n",
        "        y_true (array-like): The true labels.\n",
        "        oof_non_rounded (array-like): The continuous predictions to be rounded.\n",
        "\n",
        "    Returns:\n",
        "        float: The negative quadratic weighted kappa score between the true labels and the rounded predictions.\n",
        "    \"\"\"\n",
        "    rounded_p = threshold_Rounder(oof_non_rounded, thresholds)\n",
        "    return -quadratic_weighted_kappa(y_true, rounded_p)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4972460",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-17T16:37:28.091457Z",
          "iopub.status.busy": "2024-12-17T16:37:28.091098Z",
          "iopub.status.idle": "2024-12-17T16:37:28.100821Z",
          "shell.execute_reply": "2024-12-17T16:37:28.100130Z"
        },
        "papermill": {
          "duration": 0.04708,
          "end_time": "2024-12-17T16:37:28.102304",
          "exception": false,
          "start_time": "2024-12-17T16:37:28.055224",
          "status": "completed"
        },
        "tags": [],
        "id": "a4972460"
      },
      "outputs": [],
      "source": [
        "## Train and get predict function\n",
        "def train_predict(model, train_data, test_data):\n",
        "    \"\"\"\n",
        "    Trains a model using Stratified K-Fold cross-validation, evaluates the performance using\n",
        "    quadratic weighted kappa (QWK) score, and makes predictions on the test data.\n",
        "\n",
        "    This function performs the following steps:\n",
        "    1. Splits the training data into K folds and trains the model on each fold.\n",
        "    2. Evaluates the model on both training and validation sets using quadratic weighted kappa.\n",
        "    3. Makes predictions on the test data and aggregates the results from all folds.\n",
        "    4. Optimizes thresholds for classification using a quadratic weighted kappa score.\n",
        "    5. Returns the final predictions and the trained model.\n",
        "\n",
        "    Parameters:\n",
        "        model (sklearn.base.Estimator): The model to be trained and evaluated.\n",
        "        train_data (pd.DataFrame): The training data containing features and the target label 'sii'.\n",
        "        test_data (pd.DataFrame): The test data to make predictions on.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame with the final predictions for the test data.\n",
        "        model: The trained model after the last fold.\n",
        "        float: The average validation QWK score across all folds.\n",
        "    \"\"\"\n",
        "\n",
        "    # Align train and test input data\n",
        "    X = train_data.drop(columns=['sii'])\n",
        "    y = train_data['sii']\n",
        "\n",
        "    # Define K-Fold cross-validation\n",
        "    SKF = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
        "\n",
        "    train_his = []\n",
        "    val_his = []\n",
        "\n",
        "    oof_non_rounded = np.zeros(len(y), dtype=float)\n",
        "    oof_rounded = np.zeros(len(y), dtype=int)\n",
        "    test_preds = np.zeros((len(test_data), N_SPLITS))\n",
        "\n",
        "    for fold, (train_index, val_index) in enumerate(tqdm(SKF.split(X, y), desc=\"Train progress\", total = N_SPLITS)):\n",
        "        # Determine the data for the fold\n",
        "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
        "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "        # Train the model\n",
        "        model_ = clone(model)  # Clone the model to ensure independence at each fold\n",
        "        model_.fit(X_train, y_train)\n",
        "\n",
        "        # Compute errors\n",
        "        y_train_pred = model_.predict(X_train)\n",
        "        y_val_pred = model_.predict(X_val)\n",
        "\n",
        "        oof_non_rounded[val_index] = y_val_pred\n",
        "        y_train_pred_rounded = y_train_pred.round(0).astype(int)\n",
        "        y_val_pred_rounded = y_val_pred.round(0).astype(int)\n",
        "        oof_rounded[val_index] = y_val_pred_rounded\n",
        "\n",
        "        # Evaluate the model performance\n",
        "        train_kappa = quadratic_weighted_kappa(y_train, y_train_pred_rounded)\n",
        "        val_kappa = quadratic_weighted_kappa(y_val, y_val_pred_rounded)\n",
        "\n",
        "        train_his.append(train_kappa)\n",
        "        val_his.append(val_kappa)\n",
        "\n",
        "        test_preds[:, fold] = model_.predict(test_data)\n",
        "\n",
        "        print(f\"Fold {fold+1} - Train QWK: {train_kappa:.4f}, Validation QWK: {val_kappa:.4f}\")\n",
        "\n",
        "    print(f\"Mean Train QWK --> {np.mean(train_his):.4f}\")\n",
        "    print(f\"Mean Validation QWK ---> {np.mean(val_his):.4f}\")\n",
        "\n",
        "    KappaOPtimizer = minimize(evaluate_predictions,\n",
        "                              x0=[0.5, 1.5, 2.5], args=(y, oof_non_rounded),\n",
        "                              method='Nelder-Mead')\n",
        "\n",
        "    oof_tuned = threshold_Rounder(oof_non_rounded, KappaOPtimizer.x)\n",
        "    tKappa = quadratic_weighted_kappa(y, oof_tuned)\n",
        "\n",
        "    print(f\"----> || Optimized QWK SCORE :: {Fore.CYAN}{Style.BRIGHT} {tKappa:.3f}{Style.RESET_ALL}\")\n",
        "\n",
        "    tpm = test_preds.mean(axis=1)\n",
        "    tpTuned = threshold_Rounder(tpm, KappaOPtimizer.x)\n",
        "\n",
        "    submission = pd.DataFrame({\n",
        "        'id': sample['id'],\n",
        "        'sii': tpTuned\n",
        "    })\n",
        "\n",
        "    return submission, model_, np.mean(val_his)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fa3a728",
      "metadata": {
        "papermill": {
          "duration": 0.035256,
          "end_time": "2024-12-17T16:37:28.254691",
          "exception": false,
          "start_time": "2024-12-17T16:37:28.219435",
          "status": "completed"
        },
        "tags": [],
        "id": "6fa3a728"
      },
      "source": [
        "## 4.1 XGboost  + LightGBM + CatBoost\n",
        "Initing model section."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e76fc8bf",
      "metadata": {
        "papermill": {
          "duration": 0.034842,
          "end_time": "2024-12-17T16:37:28.324553",
          "exception": false,
          "start_time": "2024-12-17T16:37:28.289711",
          "status": "completed"
        },
        "tags": [],
        "id": "e76fc8bf"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f65057a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-17T16:37:28.395573Z",
          "iopub.status.busy": "2024-12-17T16:37:28.395238Z",
          "iopub.status.idle": "2024-12-17T16:37:28.406010Z",
          "shell.execute_reply": "2024-12-17T16:37:28.405307Z"
        },
        "papermill": {
          "duration": 0.048498,
          "end_time": "2024-12-17T16:37:28.407515",
          "exception": false,
          "start_time": "2024-12-17T16:37:28.359017",
          "status": "completed"
        },
        "tags": [],
        "id": "4f65057a"
      },
      "outputs": [],
      "source": [
        "# Create model instances\n",
        "LightGBM_Model = LGBMRegressor(**LightGBM_Params)\n",
        "XGBoost_Model = XGBRegressor(**XGB_Params)\n",
        "CatBoost_Model = CatBoostRegressor(**CatBoost_Params)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb1b2603",
      "metadata": {
        "papermill": {
          "duration": 0.034401,
          "end_time": "2024-12-17T16:37:28.476457",
          "exception": false,
          "start_time": "2024-12-17T16:37:28.442056",
          "status": "completed"
        },
        "tags": [],
        "id": "cb1b2603"
      },
      "source": [
        "## Calc weight for each model to vote"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e65eefc",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-17T16:37:28.547933Z",
          "iopub.status.busy": "2024-12-17T16:37:28.547600Z",
          "iopub.status.idle": "2024-12-17T16:37:28.552056Z",
          "shell.execute_reply": "2024-12-17T16:37:28.551266Z"
        },
        "papermill": {
          "duration": 0.042735,
          "end_time": "2024-12-17T16:37:28.553622",
          "exception": false,
          "start_time": "2024-12-17T16:37:28.510887",
          "status": "completed"
        },
        "tags": [],
        "id": "2e65eefc"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, X_test, y_test):\n",
        "    # Predicting\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calc score\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    return rmse, mae, r2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6018242",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-17T16:37:28.624192Z",
          "iopub.status.busy": "2024-12-17T16:37:28.623890Z",
          "iopub.status.idle": "2024-12-17T16:37:43.024109Z",
          "shell.execute_reply": "2024-12-17T16:37:43.023088Z"
        },
        "papermill": {
          "duration": 14.437761,
          "end_time": "2024-12-17T16:37:43.026283",
          "exception": false,
          "start_time": "2024-12-17T16:37:28.588522",
          "status": "completed"
        },
        "tags": [],
        "id": "f6018242"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "# Declare models\n",
        "models = {\n",
        "    \"LightGBM_Model\": LightGBM_Model,\n",
        "    \"XGBoost_Model\": XGBoost_Model,\n",
        "    \"CatBoost_Model\": CatBoost_Model,\n",
        "}\n",
        "\n",
        "X = train_combine.drop(columns=['sii'])\n",
        "y = train_combine['sii']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# Saving result array\n",
        "results = []\n",
        "\n",
        "# Training and evaluating models\n",
        "for name, model in models.items():\n",
        "    # training model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # evaluating\n",
        "    rmse, mae, r2 = evaluate_model(model, X_test, y_test)\n",
        "\n",
        "    # Saving results\n",
        "    results.append((name, rmse, mae, r2))\n",
        "\n",
        "    # Presenting current model's result\n",
        "    print(f\"Model: {name}\")\n",
        "    print(f\"  RMSE: {rmse:.4f}\")\n",
        "    print(f\"  MAE: {mae:.4f}\")\n",
        "    print(f\"  R2: {r2:.4f}\")\n",
        "    print(\"-\" * 30)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "758dd87c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-17T16:37:43.096903Z",
          "iopub.status.busy": "2024-12-17T16:37:43.096572Z",
          "iopub.status.idle": "2024-12-17T16:37:43.104391Z",
          "shell.execute_reply": "2024-12-17T16:37:43.103448Z"
        },
        "papermill": {
          "duration": 0.044823,
          "end_time": "2024-12-17T16:37:43.106138",
          "exception": false,
          "start_time": "2024-12-17T16:37:43.061315",
          "status": "completed"
        },
        "tags": [],
        "id": "758dd87c"
      },
      "outputs": [],
      "source": [
        "results_df = pd.DataFrame(results, columns=[\"Model\", \"RMSE\", \"MAE\", \"R2\"]).sort_values(by=\"RMSE\")\n",
        "\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine models using Voting Regressor\n",
        "voting_model = VotingRegressor(estimators=[\n",
        "    ('lightgbm', LightGBM_Model),\n",
        "    ('xgboost', XGBoost_Model),\n",
        "    ('catboost', CatBoost_Model),\n",
        "], weights=[4.0,4.0,5.0])"
      ],
      "metadata": {
        "id": "R1wptF4TjD0o"
      },
      "id": "R1wptF4TjD0o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "38160da3",
      "metadata": {
        "papermill": {
          "duration": 0.034709,
          "end_time": "2024-12-17T16:37:43.328234",
          "exception": false,
          "start_time": "2024-12-17T16:37:43.293525",
          "status": "completed"
        },
        "tags": [],
        "id": "38160da3"
      },
      "source": [
        "## Submission\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cebbb17",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-17T16:37:43.398328Z",
          "iopub.status.busy": "2024-12-17T16:37:43.398034Z",
          "iopub.status.idle": "2024-12-17T16:38:50.010475Z",
          "shell.execute_reply": "2024-12-17T16:38:50.009604Z"
        },
        "papermill": {
          "duration": 66.649786,
          "end_time": "2024-12-17T16:38:50.012385",
          "exception": false,
          "start_time": "2024-12-17T16:37:43.362599",
          "status": "completed"
        },
        "tags": [],
        "id": "6cebbb17"
      },
      "outputs": [],
      "source": [
        "Submission1, model, val = train_predict(voting_model, train_combine, test_combine)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e66aa395",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-17T16:38:50.163114Z",
          "iopub.status.busy": "2024-12-17T16:38:50.162853Z",
          "iopub.status.idle": "2024-12-17T16:38:50.172134Z",
          "shell.execute_reply": "2024-12-17T16:38:50.171231Z"
        },
        "papermill": {
          "duration": 0.047712,
          "end_time": "2024-12-17T16:38:50.173789",
          "exception": false,
          "start_time": "2024-12-17T16:38:50.126077",
          "status": "completed"
        },
        "tags": [],
        "id": "e66aa395"
      },
      "outputs": [],
      "source": [
        "Submission1['sii'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "405eff9f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-17T16:38:50.250386Z",
          "iopub.status.busy": "2024-12-17T16:38:50.250131Z",
          "iopub.status.idle": "2024-12-17T16:38:50.256460Z",
          "shell.execute_reply": "2024-12-17T16:38:50.255881Z"
        },
        "papermill": {
          "duration": 0.046607,
          "end_time": "2024-12-17T16:38:50.258087",
          "exception": false,
          "start_time": "2024-12-17T16:38:50.211480",
          "status": "completed"
        },
        "tags": [],
        "id": "405eff9f"
      },
      "outputs": [],
      "source": [
        "Submission1.to_csv('submission.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6737b5a8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-17T16:38:50.329139Z",
          "iopub.status.busy": "2024-12-17T16:38:50.328439Z",
          "iopub.status.idle": "2024-12-17T16:38:50.336541Z",
          "shell.execute_reply": "2024-12-17T16:38:50.335824Z"
        },
        "papermill": {
          "duration": 0.045106,
          "end_time": "2024-12-17T16:38:50.338044",
          "exception": false,
          "start_time": "2024-12-17T16:38:50.292938",
          "status": "completed"
        },
        "tags": [],
        "id": "6737b5a8"
      },
      "outputs": [],
      "source": [
        "Submission1"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "databundleVersionId": 9643020,
          "sourceId": 81933,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30805,
      "isGpuEnabled": true,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 215.424802,
      "end_time": "2024-12-17T16:38:53.622349",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-12-17T16:35:18.197547",
      "version": "2.6.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
